#!/usr/bin/env python
import os
import sys
import shutil
import argparse
import ConfigParser
from glob import glob
import pandas as pd

parser = argparse.ArgumentParser(description="Build directories and config files for Virtual Screening (4th stage)")

parser.add_argument('-l',
    type=str,
    dest='input_files_l',
    nargs='+',
    metavar='FILE',
    default=['compounds.csv'],
    help='ligand file(s): .mol2, .csv (default: compounds.csv)')

parser.add_argument('-r',
    type=str,
    dest='input_files_r',
    nargs='+',
    metavar='FILE',
    default=['targets.csv'], 
    help = 'target file(s): .pdb, .csv (default: targets.csv)')

parser.add_argument('-f',
    type=str,
    dest='config_file',
    metavar='FILE',
    default='config.ini',
    help='config file: .ini')

parser.add_argument('-build_scripts',
    action='store_true',
    dest='build_scripts',
    default=False,
    help='Build scripts to be submitted to SLURM scheduler')

parser.add_argument('-copy',
    action='store_true',
    dest='copy',
    default=False,
    help='Copy input files into folders (not recommended for large libraries)')

parser.add_argument('-s',
    dest='sitecsv',
    type=str,
    metavar='FILE',
    default='sites.csv',
    help='csvfile with binding sites: .csv (default: sites.csv)')

parser.add_argument('-w',
    dest='rundir',
    type=str,
    default='vs',
    metavar='DIRECTORY NAME',
    help='name of directory created for virtual screening')

others = parser.add_argument_group('arguments to build scripts')

others.add_argument('-p',
    dest='partition',
    type=str,
    default='serial',
    metavar='NAME',
    help='SLURM Partition name.')

others.add_argument('-t',
    dest='time',
    type=str,
    default='24:00:00',
    metavar='TIME',
    help='Approx. time needed for a single job in hh:mm:ss or dd-hh:mm format!')

others.add_argument('-wt',
    dest='walltime',
    type=str,
    default='24:00:00',
    metavar='WALLTIME',
    help='Max. walltime in hh:mm:ss or dd-hh:mm format used for slurm scripts (default: 24:00:00)')

def get_number_of_compounds(file_l):
    suffix, ext = os.path.splitext(file_l)
    if ext == '.mol2':
        # count number of lines with @<TRIPOS>ATOM
        nligs = subprocess.check_output('fgrep -c "@<TRIPOS>ATOM" %s'%file_l, shell=True)
    else:
        raise IOError("Extension not recognized for ligand file!")

    nligs = int(nligs)
    return nligs

def slurm_to_seconds(string):

    # check if days are provided
    string_s = string.split("-")
    if len(string_s) == 2:
        days = int(string_s[0])
        string_s_s = string_s[1].split(":")
        if len(string_s_s) == 2:
            hours = int(string_s_s[0])
            minutes = int(string_s_s[1])
        elif len(string_s_s) == 1:
            hours = int(string_s_s[0])
            minutes = 0
        else:
            raise Exception("SLURM time format %s not recognized"%string)
        seconds = 0
    elif len(string_s) == 1:
        string_s_s = string_s[0].split(":")
        days = 0
        if len(string_s_s) == 3:
            hours = int(string_s_s[0])
            minutes = int(string_s_s[1])
            seconds = int(string_s_s[2])
        elif len(string_s_s) == 2:
            hours = int(string_s_s[0])
            minutes = int(string_s_s[1])
            seconds = 0
        else:
            raise Exception("SLURM time format %s not recognized"%string)

    time = days*24*3600 + hours*3600 + minutes*60 + seconds
    return time

def seconds_to_slurm(seconds):

    days = seconds/(24*3600)
    hours = (time - days*24*3600)/3600 
    minutes = (time - days*24*3600 - hours*3600)/60
    seconds = time - days*24*3600 - hours*3600 - minutes*60

    if seconds != 0:
        minutes += 1
        seconds = 0

    days_str = str(days)
    hours_str = str(hours)
    minutes_str = str(minutes)

    if len(hours_str) == 1:
        hours_str = '0' + hours_str
    if len(minutes_str) == 1: 
        minutes_str = '0' + minutes_str

    if days_str == '0':
       slurm_time = '%s-%s:%s'%(days_str, hours_str, minutes_str)
    else:
       slurm_time = '%s:%s:00'%(hours_str, minutes_str)
    return slurm_time

args = parser.parse_args()

exts = list(set([os.path.splitext(ff)[1] for ff in args.input_files_r]))
if len(exts) != 1: # if more than one extension provided
    raise ValueError("All files specified with -r option must have the same extension!")

# check target input files
input_files_r = []
if exts[0] == '.pdb': # if input files are pdbfiles
    for file_r in args.input_files_r:
        if os.path.exists(file_r):
            input_files_r.append(os.path.abspath(file_r))
        else:
            raise ValueError("File %s not found!"%(file_r))

    ntargets = len(input_files_r)
    nid_digits = max(3, len(str(ntargets)))
    targetids = []

    for jdx, file_r in enumerate(input_files_r):
        targetids.append('target'+(nid_digits-len(str(jdx+1)))*'0' + str(jdx+1))
    is_csvfile_r = False
elif exts[0] == '.csv': # if input files is the csvfile
    if len(args.input_files_r) != 1:
        raise ValueError("More than 1 csvfile specified with -r option.")

    df_targets = pd.read_csv(args.input_files_r[0])
    input_files_r = [os.path.abspath(ff) for ff in list(df_targets['pdbfile'])]
    ntargets = len(input_files_r)
    targetids = list(df_targets['targetID'])
    is_csvfile_r = True
else:
    raise IOError("Extension of files used with -r option not recognized!")

exts_l = list(set([os.path.splitext(ff)[1] for ff in args.input_files_l]))
if len(exts_l) != 1: # if more than one extension provided
    raise ValueError("All files specified with -l option must have the same extension!")

# check ligand input files
input_files_l = []
if exts_l[0] == '.mol2': # if input files are .mol2
    for file_l in args.input_files_l:
        if os.path.exists(file_l):
            input_files_l.append(os.path.abspath(file_l))
        else:
            raise ValueError("File %s not found!"%(file_l))

    nligands = len(input_files_l)
    nid_digits = max(3, len(str(nligands)))
    ligandids = []

    for jdx, file_r in enumerate(input_files_l): 
        nligands_file_l = get_number_of_compounds(file_l)
        if nligands_file_l == 1:
            ligandids.append('lig'+(nid_digits-len(str(jdx+1)))*'0' + str(jdx+1))
        else:
            raise IOError("Every ligand file should contain at least 1 structure, or use the prepare_compounds routine!")
    is_csvfile_l = False
    use_isomer_folder = False

elif exts_l[0] == '.csv': # if input files is a csvfile
    if len(args.input_files_l) != 1:
        raise ValueError("More than 1 csvfile specified with -l option.")

    df_ligands = pd.read_csv(args.input_files_l[0])
    input_files_l = [os.path.abspath(ff) for ff in list(df_ligands['mol2file'])]
    nligands = len(input_files_l)
    ligandids = list(df_ligands['ligID'])
    isomers = list(df_ligands['isomer'])

    is_csvfile_l = True
    if all(x==1 for x in isomers):
        use_isomer_folder = False
    else:
        use_isomer_folder = True
else:
    raise IOError("Extension of files used with -r option not recognized!")

if not os.path.isfile(args.config_file):
    raise ValueError("Config file %s not found!"%args.config_file)

def update_config_file(new_config_file, config_file, label_r, csvfile):
    """Update binding site parameters in config file"""

    # create tmp config file name from original config file
    tmp_config_file = list(os.path.splitext(new_config_file))
    tmp_config_file.insert(1,'_tmp')
    tmp_config_file = ''.join(tmp_config_file)

    # remove section 'SITE' and option site in DOCKING section of config file if exists
    with open(tmp_config_file, 'w') as tmpf:
        with open(config_file, 'r') as newf:
            isdock = False
            sitesection = False
            docksection = False
            for line in newf:
                # check if still in section SITE*
                if line.startswith('[SITE'):
                    sitesection = True
                if sitesection and line.startswith('[') and not line.startswith('[SITE'): # new section has been reached
                    sitesection = False
                # check if still in section DOCKING
                if line.startswith('[DOCKING]'):
                    docksection = True
                    isdock = True
                if docksection and line.startswith('[') and not line.startswith('[DOCKING]'): # new section has been reached
                    docksection = False
                # check if option line in section DOCKING
                if line.strip().startswith('site') and docksection:
                    siteline = True
                else:
                    siteline = False
                if not sitesection and not siteline:
                    tmpf.write(line)
    shutil.move(tmp_config_file, new_config_file)

    df = pd.read_csv(csvfile)
    rows = df[df['target'] == label_r]

    nsites = len(rows)
    if nsites == 1:
         # add new sections 'SITE' and option site
        with open(tmp_config_file, 'w') as tmpf:
            with open(new_config_file, 'r') as newf:
                for line in newf:
                    tmpf.write(line)
                for row in rows.iterrows():
                    section = 'SITE'
                    center_conf = row[1]['center']
                    boxsize_conf = row[1]['size']

                    newsite_section = """
[%(section)s]
center = %(center_conf)s
boxsize = %(boxsize_conf)s"""% locals()
                    tmpf.write(newsite_section+'\n')
    elif nsites > 1:
        # add new sections 'SITE' and option site
        with open(tmp_config_file, 'w') as tmpf:
            with open(new_config_file, 'r') as newf:
                for line in newf:
                    tmpf.write(line)
                    if line.startswith('[DOCKING]'):
                        tmpf.write('site = ' + ', '.join(['site%s'%int(row[1]['site']) for row in rows.iterrows()])+'\n')
                for row in rows.iterrows():
                    section = 'SITE' + str(int(row[1]['site']))
                    center_conf = row[1]['center']
                    boxsize_conf = row[1]['size']

                    newsite_section = """
[%(section)s]
center = %(center_conf)s
boxsize = %(boxsize_conf)s"""% locals()
                    tmpf.write(newsite_section+'\n')
    shutil.move(tmp_config_file, new_config_file)

rundir = args.rundir

# always overwrite by default
shutil.rmtree(rundir, ignore_errors=True)
os.mkdir(rundir)

config_file_basename = os.path.basename(args.config_file)

# copy config files
configdir = 'config'
shutil.rmtree(configdir, ignore_errors=True)
os.mkdir(configdir)
config_suff, config_ext = os.path.splitext(config_file_basename)

config_files = []
for idx, file_r in enumerate(input_files_r):
    recid = targetids[idx]
    new_config_file = configdir + '/' + config_suff + '_%s'%(idx+1) + config_ext
    update_config_file(new_config_file, args.config_file, recid, args.sitecsv)
    config_files.append(new_config_file)

for jdx in range(nligands): #, file_l in enumerate(input_files_l):
    ligid = ligandids[jdx]
    for idx in range(ntargets): # file_r in enumerate(input_files_r):
        recid = targetids[idx]
        if use_isomer_folder:
            workdir = rundir + '/' + ligid + '/' + recid + '/isomer' + str(isomers[jdx])
        else:
            workdir = rundir + '/' + ligid + '/' + recid

        os.makedirs(workdir)
        # create list of relative paths for targets and receptors
        if jdx == 0 and idx == 0:
            input_files_l_rel = []
            for file_l in input_files_l:
                input_files_l_rel.append(os.path.relpath(file_l, workdir))

            input_files_r_rel = []
            for file_r in input_files_r:
                input_files_r_rel.append(os.path.relpath(file_r, workdir))

            config_files_rel = []
            for file_c in config_files:
                config_files_rel.append(os.path.relpath(file_c, workdir))

        if args.copy:
            shutil.copyfile(input_files_l[jdx], workdir+'/ligand.mol2')
            shutil.copyfile(input_files_r[idx], workdir+'/protein.pdb')
            shutil.copyfile(config_files[idx], workdir+'/config.ini')
            script = """#!/bin/bash
rundock -f config.ini -l ligand.mol2 -r protein.pdb
"""
        else:
            script = """#!/bin/bash
rundock -f %s -l %s -r %s
"""%(config_files_rel[idx], input_files_l_rel[jdx], input_files_r_rel[idx])
        with open(workdir+"/run.slurm", 'w') as slurmf:
            slurmf.write(script)

if args.build_scripts:
    # create jobs to be submitted
    single_job_time_sec = slurm_to_seconds(args.time)
    walltime_sec = slurm_to_seconds(args.walltime)
    
    time_all_targets = single_job_time_sec*ntargets
    
    if use_isomer_folder:
        isomerdir = '/isomer*'
    else:
        isomerdir = ''
    
    scriptdir = 'to_submit'
    shutil.rmtree(scriptdir, ignore_errors=True)
    os.mkdir(scriptdir)
    
    if time_all_targets <= walltime_sec:
        nligands_per_job = int(walltime_sec/time_all_targets)
        nscripts = nligands/nligands_per_job
    
        for idx in range(nscripts):
            idx_first = idx*nligands_per_job
            idx_last = (idx+1)*nligands_per_job-1

            workdirs = []
            for jdx in range(idx_first, idx_last+1):
                dir = args.rundir + '/' + ligandids[jdx] + '/target*'
                if use_isomer_folder:
                    dir += '/isomer' + str(isomers[jdx])
                workdirs.append(dir)

            with open(scriptdir+'/run_vs_%i.slurm'%(idx+1), 'w') as ff:
                ff.write("""#!/bin/bash
#SBATCH --time=%s
#SBATCH --partition=%s
#SBATCH --job-name="vs%s"
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --nodes=1

dirs=`echo %s`
curdir=`pwd`

for dir in $dirs; do
  cd $dir
  bash run.slurm
  cd $curdir
done\n"""%(args.walltime, args.partition, idx+1, ' '.join(workdirs)))

        nligands_last_job = nligands - nscripts*nligands_per_job
 
        if nligands_last_job != 0:
            idx_first = nscripts*nligands_per_job
            idx_last = nscripts*nligands_per_job + nligands_last_job

            workdirs = []
            for jdx in range(idx_first, idx_last):
                dir = args.rundir + '/' + ligandids[jdx] + '/target*'
                if use_isomer_folder:
                    dir += '/isomer' + str(isomers[jdx])
                workdirs.append(dir)

            with open(scriptdir+'/run_vs_%i.slurm'%(nscripts+1), 'w') as ff:
                ff.write("""#!/bin/bash
#SBATCH --time=%s
#SBATCH --partition=%s
#SBATCH --job-name="vs%s"
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --nodes=1

dirs=`echo %s`
curdir=`pwd`

for dir in $dirs; do
  cd $dir
  bash run.slurm
  cd $curdir
done\n"""%(args.walltime, args.partition, nscripts+1, ' '.join(workdirs)))
